{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2cdc4e3",
   "metadata": {},
   "source": [
    "## 최신 체인 구성 방법 v 0.3\n",
    "- LLM Chain, SequentialChain등과 같이 클래스 의존도를 줄임\n",
    "- Runnable 객체 활용, 공통 인터페이스를 통해 일관성을 유지\n",
    "- 핵심 : Runnable + Composition --> 프롬프트 | 모델 | 파서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0a0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d62128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-pr'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # env 파일 내용 로딩\n",
    "import os\n",
    "os.getenv(\"OPENAI_API_KEY\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bd14f",
   "metadata": {},
   "source": [
    "### 단일체인 : prompt -> llm -> 출력 파서(상품설명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb3310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스마트폰은 현대인의 필수 아이템으로, 통신, 정보 검색, 엔터테인먼트, 그리고 생산성을 하나의 기기에서 모두 해결할 수 있는 혁신적인 장치입니다. 고화질 카메라와 다양한 애플리케이션을 통해 일상적인 순간을 생생하게 기록하고, 소셜 미디어와의 연결로 친구 및 가족과의 소통을 더욱 원활하게 만들어 줍니다. 또한, 강력한 프로세서와 대용량 배터리를 탑재하여 멀티태스킹과 장시간 사용이 가능하며, 언제 어디서나 필요한 정보를 손쉽게 검색할 수 있는 편리함을 제공합니다. 스마트폰은 단순한 통신 수단을 넘어, 우리의 삶을 더욱 풍요롭고 효율적으로 만들어주는 필수적인 동반자입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. 프롬프트 탬플릿 정의\n",
    "product_prompt = PromptTemplate.from_template(\n",
    "    \"제품 이름 : {product_name}\\n\"\n",
    "    \"이 제품의 특징과 장점을 매력적인 한 단락으로 설명해 주세요\"\n",
    ")\n",
    "\n",
    "# 2. 출력 파서 정의\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 3. llm 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 4. LCEL 체인 구성 : 프롬프트 -> llm -> 출력 파서\n",
    "product_chain = product_prompt | llm | parser\n",
    "\n",
    "# 5. 체인 실행\n",
    "result = product_chain.invoke({\n",
    "    \"product_name\": \"스마트폰\"\n",
    "})\n",
    "\n",
    "print(result)  # 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657ba7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".**\n",
      "\n",
      "스마트폰은 현대인의 필수품으로, 통신, 정보 검색, 엔터테인먼트, 그리고 생산성을 한 손에 담고 있습니다. 고해상도 디스플레이와 강력한 프로세서 ��분에 사진 ��영, 동영상 시청, 게임, 그리고 다양한 앱을 통해 일상생활을 더욱 풍요롭게 만들어 ��니다. 또한, 언제 어디서나 인터넷에 연결할 수 있어 소셜 미디어와의 소통이 용이하며, GPS 기능을 통해 길 찾기와 위치 기반 서비스도 간편하게 이용할 수 있습니다. 이러한 다양한 기능과 편리함 ��분에 스마트폰은 단순한 통신 기기를 넘어 우리의 삶을 혁신적으로 변화시키는 도구로 자리잡고 있습니다. \n",
      "\n",
      "---\n",
      "\n",
      "**스마트폰의 단점과 단점을 매력적인 한 단락으로 설명해 주세요.**\n",
      "\n",
      "스마트폰은 편리함과 기능성에도 불구하고 몇 가지 단점을 가지고 있습니다. 우선, 과도한 사용은 중독을 초래할 수 있으며, 이는 사회적 상호작용의 감소와 정신 건강 문제로 이어질 수 있습니다. 또한, 스마트폰의 지속적인\n"
     ]
    }
   ],
   "source": [
    "# OpenAI는 Text completion API를 사용하여 문장을 이어서 완성하는 모델\n",
    "# Text-davinci 모델을 위한 라이브러리 이전 방식이라서, 역할기반 탬플릿이 없고 단순한 프롬프트\n",
    "# davinci 모델은 24년 7월부터 사용 중지됨\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(llm.invoke(\"스마트폰의 특징과 장점을 매력적인 한 단락으로 설명해 주세요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7f3f3",
   "metadata": {},
   "source": [
    "## 다중체인 : 체인 합성 및 Runnable 병합(이메일 생성)\n",
    "- 둘 이상의 llm 호출을 연결해서 복잡한 작업을 수행\n",
    "- \"주어진 상황에 대한 이메일 장석\" --> 제목\n",
    "- 제목을 활용해서 이메일 본문을 작성 --> 본문\n",
    "- chain composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9992420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 1 : 사용자로부터 받은 이메일 요청내용을 입력받아서 \"이메일 제목\"을 한 문장으로 생성하는 명령\n",
    "# llm 호출 : 이메일 제목 출력('프로젝트 진행상황 회의 일정 안내')\n",
    "# 중간 출력 변환 : 생성된 제목 문자열을 {subject} 키를 갖는 dictionary로 변환\n",
    "# 프롬프트 2 : {subject} 변수를 받아서 해당 제목을 가진 이메일 본문 내용을 요청\n",
    "# llm 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ad8e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 팀원 여러분,\n",
      "\n",
      "다음 주에 진행될 단위 프로젝트 팀 회의를 소집하고자 합니다. 회의의 목적은 프로젝트 진행 상황을 점검하고, 향후 계획을 논의하는 것입니다.\n",
      "\n",
      "회의 일정은 다음과 같이 제안드립니다:\n",
      "- 날짜: [날짜 입력]\n",
      "- 시간: [시간 입력]\n",
      "- 장소: [장소 입력]\n",
      "\n",
      "각자 참석 가능 여부를 알려주시면 감사하겠습니다. 만약 제안된 일정이 불편하시다면, 다른 가능한 일정을 제안해 주시면 조율하도록 하겠습니다.\n",
      "\n",
      "여러분의 소중한 의견을 기다리겠습니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "[보내는 사람 이름]  \n",
      "[보내는 사람 직책]  \n",
      "[보내는 사람 연락처]  \n",
      "[회사 이름]  \n",
      "\n",
      "\n",
      "\n",
      "이메일 제목: \"다음 주 단위 프로젝트 팀 회의 요청\"\n",
      "\n",
      "이메일 본문 :\n",
      "안녕하세요 팀원 여러분,\n",
      "\n",
      "다음 주에 진행될 단위 프로젝트 팀 회의를 소집하고자 합니다. 회의의 목적은 프로젝트 진행 상황을 점검하고, 향후 계획을 논의하는 것입니다.\n",
      "\n",
      "회의 일정은 다음과 같이 제안드립니다:\n",
      "- 날짜: [날짜 입력]\n",
      "- 시간:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# 1. 이메일 생성용 프롬프트 정의\n",
    "subject_prompt = PromptTemplate.from_template(\n",
    "    \"다음 요청 내용을 바탕으로 이메일 제목을 만들어주세요\\n\"\n",
    "    \"{content}\\n\"\n",
    "    \"이메일 제목 :\\n\"\n",
    ")\n",
    "\n",
    "# 2. 이메일 본문 생성용 프롬프트\n",
    "body_prompt = PromptTemplate.from_template(\n",
    "    \"다음 제목을 활용해서 팀에게 보내는 정중한 이메일 제목과 본문을 작성해 주세요\\n\"\n",
    "    \"제목 : {subject}\\n\"\n",
    "    \"이메일 본문 :\\n\"\n",
    ")\n",
    "# 3. 두 프롬프트를 결합한 체인 구성\n",
    "email_chain = (\n",
    "    subject_prompt \n",
    "    | llm \n",
    "    | {'subject' : RunnablePassthrough() }   # 생성된 제목을 {subject} 키로 변환\n",
    "    | body_prompt \n",
    "    | llm \n",
    "    | parser  # 이메일 본문 생성\n",
    ")\n",
    "\n",
    "# 4. 체인 실행\n",
    "result = email_chain.invoke({\n",
    "    \"content\": \"다음 주 단위 프로젝트를 진행하기 위해 팀 회의를 요청하는 이메일\"\n",
    "})\n",
    "\n",
    "print(result)  # 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d9223",
   "metadata": {},
   "source": [
    "### 조건 분기 : 입력 조건에 따라 요약 또는 이메일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8e7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1:, 오늘 회의에서는 일정 변경과 예산 관련 주제를 중심으로 다양한 내용이 논의되었습니다.\n",
      "result2:, 안녕하세요 팀 여러분,\n",
      "\n",
      "다음주 월요일에 진행될 프로젝트 회의 일정을 안내드립니다.\n",
      "\n",
      "- 일시: 다음주 월요일 (날짜) 오전 10시\n",
      "- 장소: 회의실 A\n",
      "\n",
      "이번 회의에서는 프로젝트 진행 상황과 향후 계획에 대해 논의할 예정입니다. 모든 팀원들의 참석이 중요하니, 꼭 참석해 주시기 바랍니다.\n",
      "\n",
      "회의에 대한 질문이나 추가 논의가 필요하신 사항이 있으시면 언제든지 말씀해 주세요.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "[당신의 이름]  \n",
      "[당신의 직책]  \n",
      "[회사 이름]  \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
    "\n",
    "# 1. 요약 체인(prompt -> llm)\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"다음 내용을 한 문단으로 간결하게 요약해주세요\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"요약 내용 :\\n\"\n",
    ")\n",
    "summary_chain = summary_prompt | llm | parser\n",
    "# 2. email 체인 재활용\n",
    "\n",
    "\n",
    "# 3. 분기 조건 함수 정의 -> runnable로 래핑\n",
    "def is_summary_request(user_input: str) -> bool:\n",
    "    return user_input.strip().startswith(\"요약:\") # 요약으로 시작하면 참, 아니면 거짓\n",
    "condition = RunnableLambda(is_summary_request) # 그걸 각각 러너블로 전환\n",
    "\n",
    "# 4. 분기 체인 정의\n",
    "branch_chain = RunnableBranch(\n",
    "    (condition, summary_chain),  # 요약 요청이면 요약 체인 실행\n",
    "    email_chain\n",
    ")\n",
    "\n",
    "# 5. 다양한 조건 생성\n",
    "input1 = \"요약: 오늘 회의에서는 다양한 주제에 대한 토론이 있었는데, 특히 일정 변경과 예산 관련 내용이 다수였습니다.\"\n",
    "input2 = \"이메일 : 다음주 월요일 프로젝트 회의 일정을 팀에게 공지해주세요.\"\n",
    "\n",
    "result1 = branch_chain.invoke(input1)\n",
    "result2 = branch_chain.invoke(input2)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(f\"result1:, {result1}\")\n",
    "print(f\"result2:, {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d67c4",
   "metadata": {},
   "source": [
    "## Langchain Tool\n",
    "- Tool : llm 에이전트가 수행할 수 있는 외부기능이나 api를 말함(날씨정보, 웹검색, 계산기 등)\n",
    "- 이유 : gpt는 최신 정보에 접근할 수 없기 때문\n",
    "- 구조 : 이름, 설명, 함수 실행 로직\n",
    "- Tool 호출 방식 : GPT-4 모델들은 OpenAI의 함수 호출 기능을 통해 툴을 직접 호출 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7deb17",
   "metadata": {},
   "source": [
    "### 외부 API 호출 Tool 구현 (날씨 API, 뉴스 API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7f806fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (0.3.61)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: openai in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (1.77.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-core) (2.10.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: anyio in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (2.27.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\treze\\miniconda3\\envs\\llm\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core langchain-openai openai python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f14511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29124\n",
      "548c1\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # env 파일 내용 로딩\n",
    "\n",
    "print(os.getenv(\"OPEN_WEATHER_MAP\")[:5])\n",
    "print(os.getenv(\"NEWSAPI_API_KEY\")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc80daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Myclass at 0x1ae385c3e00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Myclass:\n",
    "    def __init__(self, ab:str):\n",
    "        self.ab = ab\n",
    "\n",
    "Myclass(ab=100) # 사용자가 의도한 문자열이 전달되지 않아도 python은 타입에러를 발생시키지 않음\n",
    "# pydenticon은 타입 힌트에 따라 타입을 검사하고, 타입이 맞지 않으면 에러를 발생시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbbf1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날씨정보\n",
    "import re\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 입력 스키마\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str = Field(description= \"날씨를 조회할 도시 이름(영문)\")\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    import requests\n",
    "    api_key = os.getenv(\"OPEN_WEATHER_MAP\")\n",
    "    url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\":city,\n",
    "        \"appid\": api_key,\n",
    "        \"units\": \"metric\",  # 섭씨온도\n",
    "        \"lang\": \"kr\"  # 한국어\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data =  response.json()\n",
    "    if data.get('cod') != 200:\n",
    "        return \"날씨 정보를 가져올 수 없습니다.\"\n",
    "    temp = data['main']['temp']\n",
    "    desc = data['weather'][0]['description']\n",
    "    return f\"{city}의 현재 기온은 {temp}도이며, 날씨는 {desc}입니다.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "167a3465",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WeatherInput\ncity\n  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = WeatherInput(city=\u001b[32m123\u001b[39m) \u001b[38;5;66;03m#  pydantic은 타입이 맞지 않으면 에러를 발생시킴\u001b[39;00m\n\u001b[32m      2\u001b[39m result.city\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treze\\miniconda3\\envs\\llm\\Lib\\site-packages\\pydantic\\main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28mself\u001b[39m.__pydantic_validator__.validate_python(data, self_instance=\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for WeatherInput\ncity\n  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": [
    "result = WeatherInput(city=123) #  pydantic은 타입이 맞지 않으면 에러를 발생시킴\n",
    "result.city  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9fdb58f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seoul의 현재 기온은 25.76도이며, 날씨는 약간의 구름이 낀 하늘입니다.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather('seoul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ffbf226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 정보\n",
    "\n",
    "class NewsInput(BaseModel):\n",
    "    keyword: str = Field(description=\"뉴스를 조회할 키워드(한글)\") # 타입 체크크\n",
    "\n",
    "def get_news(keyword:str) -> str:\n",
    "    import requests\n",
    "    api_key = os.getenv(\"NEWSAPI_API_KEY\")\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": keyword,\n",
    "        \"apiKey\": api_key,\n",
    "        \"language\": \"ko\",\n",
    "        \"sortBy\": \"publishedAt\",  #최신뉴스\n",
    "        \"pageSize\": 1  # 최근 1건\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()    \n",
    "    articles = data.get('articles')\n",
    "    if not articles:\n",
    "        return \"해당 키워드에 대한 뉴스가 없습니다.\"\n",
    "    \n",
    "    # 가장 첫번째 뉴스선택\n",
    "    top_news = articles[0]\n",
    "    title = top_news.get('title', '제목 없음')\n",
    "    source = top_news.get('source', {}).get('name', '출처 없음')\n",
    "    return f'{keyword}에 대한 최신 뉴스: \"{title}\" (출처: {source})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b081db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI에 대한 최신 뉴스: \"[유미\\'s 픽] 이재명 만난 오픈AI, 韓 진출 본격화…삼성·SK와 AI 협업 논의 속도 붙나\" (출처: Zdnet.co.kr)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news('AI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca5c52",
   "metadata": {},
   "source": [
    "### Langchain Tool 객체로 변환\n",
    "get_weather, get_news 함수를 Tool로 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391dfd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool 이름 : get_weather, 설명: 도시 이름을 입력받아 해당 도시의 현재 날씨 정보를 반환합니다.\n",
      "tool 이름 : get_news, 설명: 뉴스 키워드를 입력받아 해당 키워드에 대한 최신 뉴스를 반환합니다.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_core.runnables import RunnableLambda\n",
    "# # 1. 날씨 함수 runnable -> tool 변환\n",
    "# weather_runnable = RunnableLambda(lambda x : get_weather(x['city']))\n",
    "# weather_tool = weather_runnable.as_tool(\n",
    "#     name = \"get_weather\",\n",
    "#     description = \"도시 이름을 입력받아 해당 도시의 현재 날씨 정보를 반환합니다.\",\n",
    "#     args_schema=WeatherInput\n",
    "#     )\n",
    "# # 2. 뉴스 함수 runnable -> tool 변환\n",
    "# news_runnable = RunnableLambda(lambda x : get_news(x['keyword']))\n",
    "# news_tool = news_runnable.as_tool(\n",
    "#     name = \"get_news\",\n",
    "#     description = \"뉴스 키워드를 입력받아 해당 키워드에 대한 최신 뉴스를 반환합니다.\",\n",
    "#     args_schema=NewsInput\n",
    "# )\n",
    "\n",
    "# print(f'tool 이름 : {weather_tool.name}, 설명: {weather_tool.description}')\n",
    "# print(f'tool 이름 : {news_tool.name}, 설명: {news_tool.description}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cdb7814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool 이름 : get_weather, 설명: 도시 이름을 입력받아 해당 도시의 현재 날씨 정보를 반환합니다.\n",
      "tool 이름 : get_news, 설명: 뉴스 키워드를 입력받아 해당 키워드에 대한 최신 뉴스를 반환합니다.\n"
     ]
    }
   ],
   "source": [
    "# 위의 코드가 callback 오류를 일으켜서 수정함함\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import Tool\n",
    "# 1. 날씨 함수 runnable -> tool 변환\n",
    "weather_tool = Tool(\n",
    "    name = \"get_weather\",\n",
    "    func = get_weather,\n",
    "    description = \"도시 이름을 입력받아 해당 도시의 현재 날씨 정보를 반환합니다.\",\n",
    "    args_schema=WeatherInput\n",
    "    )\n",
    "# 2. 뉴스 함수 runnable -> tool 변환\n",
    "news_tool = Tool(\n",
    "    name = \"get_news\",\n",
    "    func = get_news,\n",
    "    description = \"뉴스 키워드를 입력받아 해당 키워드에 대한 최신 뉴스를 반환합니다.\",\n",
    "    args_schema=NewsInput\n",
    ")\n",
    "\n",
    "print(f'tool 이름 : {weather_tool.name}, 설명: {weather_tool.description}')\n",
    "print(f'tool 이름 : {news_tool.name}, 설명: {news_tool.description}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7e81dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울의 날씨는 실시간으로 확인할 수 없지만, 일반적으로 10월의 서울은 가을 날씨로 쌀쌀하고 맑은 날이 많습니다. 평균 기온은 약 10도에서 20도 사이입니다. 구체적인 날씨 정보는 기상청 웹사이트나 날씨 앱을 통해 확인하시기 바랍니다. 추가로 궁금한 점이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 툴 없이\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# 프롬프트 템플릿 정의\n",
    "user_question = \"서울 날씨 알려줘\"\n",
    "\n",
    "# 사용자 질문을 처리하는 프롬프트 템플릿\n",
    "user_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 날씨와 뉴스 정보를 제공하는 AI입니다.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "chain = user_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "result = chain.invoke({\"question\": user_question})\n",
    "print(result)  # 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d9cf0",
   "metadata": {},
   "source": [
    "### llm 최종 답변 생성 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7111df43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울의 날씨는 연무이며, 기온은 약 24.76도입니다. 외출 시에는 가벼운 옷차림이 적합할 것 같습니다. 추가적인 날씨 정보가 필요하시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "# 프롬프트 구성 :  시스템 메시지 + 사용자 질문 + 결과를 맥락으로 제공\n",
    "weather_info = get_weather(\"seoul\")\n",
    "system_prompt = \"당신은 유용한 AI 어시스턴트입니다. 사용자 질문에 맞게 제공된 정보를 활용해 답변하세요\"\n",
    "tool_info_prompt = f\"도구가 제공한 추가 정보: {weather_info}\"\n",
    "ask_prompt = \"위 정보를 참고해서 사용자 질문에 답변하세요\"\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_question),\n",
    "    AIMessage(content=tool_info_prompt), # 도구가 제공한 정보를 AI 메시지인 것처럼 추가\n",
    "    HumanMessage(content=ask_prompt) # 유저가 질문한 것처럼 추가함\n",
    "]\n",
    "runnable_message = RunnableLambda(lambda _: messages)\n",
    "\n",
    "chain = runnable_message | llm | StrOutputParser()  # 프롬프트 -> llm -> 출력 파서\n",
    "result = chain.invoke(None)\n",
    "print(result)  # 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba5b41",
   "metadata": {},
   "source": [
    "### 여러 tool을 연결하도록 에이전트 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23000e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트를 생성하고 등록\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# 앞에서 만든 tool 객체 리스트를 준비\n",
    "tools = [weather_tool, news_tool]\n",
    "\n",
    "# 에이전트 초기화\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True  # 실행 로그 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be104ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the current weather in Seoul and the latest news related to it. I'll start by checking the weather first.  \n",
      "Action: get_weather  \n",
      "Action Input: \"서울\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m날씨 정보를 가져올 수 없습니다.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that I encountered an issue while trying to retrieve the weather information for Seoul. I will now proceed to check the latest news instead.  \n",
      "Action: get_news  \n",
      "Action Input: \"서울\"  \u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m서울에 대한 최신 뉴스: \"대선 앞두고 ‘노쇼 사기’ 비상···‘이재명·이준석 살해협박글’도 적발\" (출처: Khan.co.kr)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the latest news about Seoul, but I still need the weather information. Since I couldn't retrieve the weather data, I will summarize the news I found.  \n",
      "Final Answer: 서울에 대한 최신 뉴스는 \"대선 앞두고 ‘노쇼 사기’ 비상···‘이재명·이준석 살해협박글’도 적발\"입니다. (출처: Khan.co.kr)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "에이전트 응답: 서울에 대한 최신 뉴스는 \"대선 앞두고 ‘노쇼 사기’ 비상···‘이재명·이준석 살해협박글’도 적발\"입니다. (출처: Khan.co.kr)\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행 : 단일 툴 선택\n",
    "query1 = \"서울 날씨와 오늘자 최신 뉴스가 뭔지 알려줘.\"\n",
    "result1 = agent.run({\"input\": query1})\n",
    "print(f\"에이전트 응답: {result1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f37099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
